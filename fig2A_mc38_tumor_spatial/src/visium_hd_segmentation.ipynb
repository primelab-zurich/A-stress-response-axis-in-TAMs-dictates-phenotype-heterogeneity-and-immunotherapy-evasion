{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "240a18a3-7929-4a96-ad0e-836d8d8cb35c",
   "metadata": {},
   "source": [
    "# Segmentation and Binning of single nuclei from Visium HD\n",
    "Adpated from https://www.10xgenomics.com/analysis-guides/segmentation-visium-hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadb0945-8a3d-4a3c-b4a2-6abb3d63f99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import anndata\n",
    "import geopandas as gpd\n",
    "import scanpy as sc\n",
    "\n",
    "import pathlib\n",
    "\n",
    "from tifffile import imread, imwrite\n",
    "from csbdeep.utils import normalize\n",
    "from stardist.models import StarDist2D\n",
    "from shapely.geometry import Polygon, Point\n",
    "from scipy import sparse\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "import nuclei_segmentation_plotting as nsp\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec2f380-1449-4f78-b43a-4ed23a0d49a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_name = 'B23.1556.tif'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8168f182-3401-4ea8-8f38-e7bdb0ee5253",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_to_data = pathlib.Path('..') / 'data' / 'raw'\n",
    "path_to_intermediate_data = path_to_data.parent / 'intermediate'\n",
    "path_to_intermediate_data.mkdir(parents = True, exist_ok=True)\n",
    "result_dir = pathlib.Path('..') / 'results'\n",
    "result_dir.mkdir(parents = True, exist_ok = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8724188-4af1-4eb2-82f4-bb917f596a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rois = dict()\n",
    "rois['top_left'] = (11591,8072,17200,12176)\n",
    "rois['bottom_right'] = (23288,15802,27803,19290)\n",
    "rois['bottom_right_enlarged'] = (22696,15767,27742,19310)\n",
    "rois['top_right']= (21373,8345,26435,12244)\n",
    "rois['middle'] = (14822,13042,20042,16829)\n",
    "\n",
    "\n",
    "segmentation_qc_rois = dict()\n",
    "segmentation_qc_rois['high_density'] = (22887,16780,23207,17100)\n",
    "segmentation_qc_rois['low_density'] = (25366,10611,26301,11443)\n",
    "segmentation_qc_rois['medium_density'] = (26825,16530,27354,16990)\n",
    "segmentation_qc_rois['mixed_density'] = (16022,10920,16857,11644)\n",
    "segmentation_qc_rois['middle_small_area'] = (16576,13474,17383,14212)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13636b10-5e54-483b-9d74-569f5e32ec34",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = imread(path_to_data / img_name)\n",
    "\n",
    "# Load the pretrained model\n",
    "model = StarDist2D.from_pretrained('2D_versatile_he')\n",
    "\n",
    "# Percentile normalization of the image\n",
    "# Adjust min_percentile and max_percentile as needed\n",
    "min_percentile = 2\n",
    "max_percentile = 98\n",
    "img = normalize(img, min_percentile, max_percentile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d76e2d60-fc99-45f4-9e26-f30f22ad466e",
   "metadata": {},
   "source": [
    "# Nuclei Mask and GeoDataframe Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab12a7a4-6021-4e54-92e6-62b844c38f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict cell nuclei using the normalized image\n",
    "# Adjust nms_thresh and prob_thresh as needed\n",
    "\n",
    "labels, polys = model.predict_instances_big(img, axes='YXC', block_size=4096, prob_thresh=0.1, nms_thresh=0.001, min_overlap=128, context=128, normalizer=None, n_tiles=(4,4,1)) # original: nms_thresh=0.001, prob_thresh=0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc07f9a-bcf4-4f39-8912-51ff0da0441e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list to store Polygon geometries\n",
    "geometries = []\n",
    "\n",
    "# Iterating through each nuclei in the 'polys' DataFrame\n",
    "for nuclei in range(len(polys['coord'])):\n",
    "\n",
    "    # Extracting coordinates for the current nuclei and converting them to (y, x) format\n",
    "    coords = [(y, x) for x, y in zip(polys['coord'][nuclei][0], polys['coord'][nuclei][1])]\n",
    "\n",
    "    # Creating a Polygon geometry from the coordinates\n",
    "    geometries.append(Polygon(coords))\n",
    "\n",
    "# Creating a GeoDataFrame using the Polygon geometries\n",
    "gdf = gpd.GeoDataFrame(geometry=geometries)\n",
    "gdf['id'] = [f\"ID_{i+1}\" for i, _ in enumerate(gdf.index)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d129bf-95f4-4c87-8eb3-fbfaa6403e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e70620ec-1c5e-4914-8e08-fde7f5d370fe",
   "metadata": {},
   "source": [
    "# Fig 2A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e05572f-b98d-4d17-8c82-38527eedf5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap=ListedColormap(['grey'])\n",
    "\n",
    "\n",
    "\n",
    "for name, coords in segmentation_qc_rois.items():\n",
    "    nsp.plot_mask_and_save_image(title=name,gdf=gdf,bbox=coords,cmap=cmap,img=img,output_name=result_dir / \"image_mask_{}.tif\".format(name))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba115d75-62b5-4f31-8de8-18a2e38672f3",
   "metadata": {},
   "source": [
    "# Binning Visium HD Gene Expression Data  \n",
    "In the following code block, we load the 2x2 Âµm Visium HD gene expression data and tissue position information. A GeoDataframe is then created. Be sure that the expression data and tissue position files are in the same directory as the high-resolution H&E microscope image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f526951-babe-4a09-afc0-cb4e8a0d5cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Visium HD data\n",
    "raw_h5_file = path_to_data / 'square_002um' / 'filtered_feature_bc_matrix.h5'\n",
    "adata = sc.read_10x_h5(raw_h5_file)\n",
    "\n",
    "# Load the Spatial Coordinates\n",
    "tissue_position_file = path_to_data / 'square_002um' / 'spatial' / 'tissue_positions.parquet'\n",
    "df_tissue_positions=pd.read_parquet(tissue_position_file)\n",
    "\n",
    "#Set the index of the dataframe to the barcodes\n",
    "df_tissue_positions = df_tissue_positions.set_index('barcode')\n",
    "\n",
    "# Create an index in the dataframe to check joins\n",
    "df_tissue_positions['index']=df_tissue_positions.index\n",
    "\n",
    "# Adding the tissue positions to the meta data\n",
    "adata.obs =  pd.merge(adata.obs, df_tissue_positions, left_index=True, right_index=True)\n",
    "\n",
    "# Create a GeoDataFrame from the DataFrame of coordinates\n",
    "geometry = [Point(xy) for xy in zip(df_tissue_positions['pxl_col_in_fullres'], df_tissue_positions['pxl_row_in_fullres'])]\n",
    "gdf_coordinates = gpd.GeoDataFrame(df_tissue_positions, geometry=geometry)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a834ee55-713f-42af-975a-ff0e96449c56",
   "metadata": {},
   "source": [
    "We next check each barcode to determine if they are in a cell nucleus. There is a chance that two or more cell nuclei can overlap, so to remove barcode assignment ambiguity, we will later filter to retain only barcodes that are uniquely assigned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cfcf061-a10e-430e-a74b-4f410464b45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a spatial join to check which coordinates are in a cell nucleus\n",
    "result_spatial_join = gpd.sjoin(gdf_coordinates, gdf, how='left', predicate='within')\n",
    "\n",
    "# Identify nuclei associated barcodes and find barcodes that are in more than one nucleus\n",
    "result_spatial_join['is_within_polygon'] = ~result_spatial_join['index_right'].isna()\n",
    "barcodes_in_overlaping_polygons = pd.unique(result_spatial_join[result_spatial_join.duplicated(subset=['index'])]['index'])\n",
    "result_spatial_join['is_not_in_an_polygon_overlap'] = ~result_spatial_join['index'].isin(barcodes_in_overlaping_polygons)\n",
    "\n",
    "# Remove barcodes in overlapping nuclei\n",
    "barcodes_in_one_polygon = result_spatial_join[result_spatial_join['is_within_polygon'] & result_spatial_join['is_not_in_an_polygon_overlap']]\n",
    "\n",
    "# The AnnData object is filtered to only contain the barcodes that are in non-overlapping polygon regions\n",
    "filtered_obs_mask = adata.obs_names.isin(barcodes_in_one_polygon['index'])\n",
    "filtered_adata = adata[filtered_obs_mask,:]\n",
    "\n",
    "# Add the results of the point spatial join to the Anndata object\n",
    "filtered_adata.obs =  pd.merge(filtered_adata.obs, barcodes_in_one_polygon[['index','geometry','id','is_within_polygon','is_not_in_an_polygon_overlap']], left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cc8899-0f5a-43fc-8a89-764ad5c28d65",
   "metadata": {},
   "source": [
    "Next we perform a gene-wise count summation for the custom binned data. This step will take a few minutes to execute and can vary based on the number of nuclei in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f9d521-ee79-4e43-8aa3-622621ddb69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group the data by unique nucleous IDs\n",
    "groupby_object = filtered_adata.obs.groupby(['id'], observed=True)\n",
    "\n",
    "# Extract the gene expression counts from the AnnData object\n",
    "counts = filtered_adata.X\n",
    "\n",
    "# Obtain the number of unique nuclei and the number of genes in the expression data\n",
    "N_groups = groupby_object.ngroups\n",
    "N_genes = counts.shape[1]\n",
    "\n",
    "# Initialize a sparse matrix to store the summed gene counts for each nucleus\n",
    "summed_counts = sparse.lil_matrix((N_groups, N_genes))\n",
    "\n",
    "# Lists to store the IDs of polygons and the current row index\n",
    "polygon_id = []\n",
    "row = 0\n",
    "\n",
    "# Iterate over each unique polygon to calculate the sum of gene counts.\n",
    "for polygons, idx_ in groupby_object.indices.items():\n",
    "    summed_counts[row] = counts[idx_].sum(0)\n",
    "    row += 1\n",
    "    polygon_id.append(polygons)\n",
    "\n",
    "# Create and AnnData object from the summed count matrix\n",
    "summed_counts = summed_counts.tocsr()\n",
    "grouped_filtered_adata = anndata.AnnData(X=summed_counts,obs=pd.DataFrame(polygon_id,columns=['id'],index=polygon_id),var=filtered_adata.var)\n",
    "\n",
    "%store grouped_filtered_adata\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746df5a5-1df1-47af-8fb4-9f58a552f8b8",
   "metadata": {},
   "source": [
    "# Nuclei Binning Results  \n",
    "In this demonstration, we filter the results to remove very large nuclei, which could be improperly segmented nuclei aggregates or image artifacts, and remove nuclei with too few UMI counts to make cluster interpretation and visualization easier. This step is optional and performing it will likely depend on the sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b0b86cc-ce70-49ad-ac8d-3ccd0f3efd35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store the area of each nucleus in the GeoDataframe\n",
    "gdf['area'] = gdf['geometry'].area\n",
    "\n",
    "sc.pp.calculate_qc_metrics(grouped_filtered_adata, inplace=True)\n",
    "\n",
    "# Plot the nuclei area distribution before and after filtering\n",
    "nsp.plot_nuclei_area(gdf=gdf,area_cut_off=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb7a140b-9212-4aa4-a89a-aedba3e1ae80",
   "metadata": {},
   "source": [
    "Based on the nuclei distribution we selected a value of 500 to filter the data.\n",
    "\n",
    "Next we plot the total UMI distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a117ad-81eb-48f3-9ecc-00ebe9dbb203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot total UMI distribution\n",
    "nsp.total_umi(grouped_filtered_adata, 50) # original value: 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e59066d-34e7-42f3-902a-f322fe19bc62",
   "metadata": {},
   "source": [
    "For this dataset, a total UMI cutoff of 100 was used. These values (nuclei area and UMI cutoff) may need adjustment for other datasets. Selecting appropriate cutoff values might require iteration based on the intepretation of the clustering results.\n",
    "\n",
    "The following code block filters the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b4e7c61-1d7c-44a9-ad10-50112e3d33fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mask based on the 'id' column for values present in 'gdf' with 'area' less than max_area\n",
    "max_area = 800\n",
    "mask_area = grouped_filtered_adata.obs['id'].isin(gdf[gdf['area'] < max_area].id)\n",
    "\n",
    "# Create a mask based on the 'total_counts' column for values greater than 100\n",
    "min_total_counts = 50 # original value: 100\n",
    "mask_count = grouped_filtered_adata.obs['total_counts'] > min_total_counts\n",
    "\n",
    "# Apply both masks to the original AnnData to create a new filtered AnnData object\n",
    "count_area_filtered_adata = grouped_filtered_adata[mask_area & mask_count, :]\n",
    "\n",
    "# Calculate quality control metrics for the filtered AnnData object\n",
    "sc.pp.calculate_qc_metrics(count_area_filtered_adata, inplace=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a52a66e-2236-450c-bbbb-abe14039baa8",
   "metadata": {},
   "source": [
    "# View filtered mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f245be-0fe9-4d07-8e4c-5fb597ba3f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[gdf['area'] < max_area]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68b0fa-f802-401a-81dc-3bc6e9cf1fc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the nuclei segmentation\n",
    "cmap=ListedColormap(['grey'])\n",
    "for name, coords in segmentation_qc_rois.items():\n",
    "    nsp.plot_mask_and_save_image(title=name,gdf=gdf[gdf['area'] < max_area],bbox=coords,cmap=cmap,img=img,output_name=result_dir / \"image_mask_filtered_{}.tif\".format(name))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41daab10-9bf7-4964-8254-e719da1e84a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, coords in rois.items():\n",
    "    nsp.plot_mask_and_save_image(title=name,gdf=gdf[gdf['area'] < max_area],bbox=coords,cmap=cmap,img=img,output_name=result_dir / \"image_mask_filtered_{}.tif\".format(name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffb066b6-954f-4975-8a92-8308eff3473c",
   "metadata": {},
   "source": [
    "To assess the binning results, we examine gene expression and clustering. In the next block of code, the results undergo clustering. It is important to note that the resolution parameter used in Leiden clustering may need adjustment when working with different datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa7266-e410-410a-9b4f-ec0ed52a12e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize total counts for each cell in the AnnData object\n",
    "sc.pp.normalize_total(count_area_filtered_adata, inplace=True)\n",
    "\n",
    "# Logarithmize the values in the AnnData object after normalization\n",
    "sc.pp.log1p(count_area_filtered_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b3f195-b34f-417e-addc-1af2a0db1dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify highly variable genes in the dataset using the Seurat method\n",
    "sc.pp.highly_variable_genes(count_area_filtered_adata, flavor=\"seurat\", n_top_genes=2000)\n",
    "sc.pp.pca(count_area_filtered_adata)\n",
    "\n",
    "# Build a neighborhood graph based on PCA components\n",
    "sc.pp.neighbors(count_area_filtered_adata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f2e349-4505-4dd5-92d2-2746aa656f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adjust the resolution parameter as needed for different samples\n",
    "sc.tl.leiden(count_area_filtered_adata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af074638-1d45-45e6-ae06-afd438488f2e",
   "metadata": {},
   "source": [
    "When the clustering results are plotted, we see clusters that align with morphological features (Figure 6)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdb916d-47a2-4cc6-8662-8605f40485d9",
   "metadata": {},
   "source": [
    "# Save adata and geodataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e869a4a0-dcec-4dea-aa0d-0467f172209c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_area_filtered_adata.write(path_to_intermediate_data /'count_area_filtered_adata.h5ad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe2dcdc8-5085-45e8-9246-4ead99c8142e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.to_parquet(path_to_intermediate_data / 'geodataframe.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b7f4d5-6e89-4f69-9d78-d69caa944214",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
